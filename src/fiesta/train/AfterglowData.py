"""
Method to train the surrogate models on afterglow data
"""
import os
import numpy as np
import ast
import h5py
import tqdm
from multiprocessing import Pool
from jaxtyping import Array, Float, Int

from fiesta.utils.constants import days_to_seconds, dL_at_10pc
import afterglowpy as grb


class AfterglowData:
    def __init__(self,
                 outdir: str,
                 n_training: int, 
                 n_val: int,
                 n_test: int,
                 outfile: str = "raw_data.h5",
                 parameter_distributions: dict = None,
                 jet_type: int = -1,
                 tmin: float = 1.0,
                 tmax: float = 1000.0,
                 n_times: int = 100,
                 use_log_spacing: bool = True,
                 numin: float = 1e9,
                 numax: float = 2.5e18,
                 n_nu: int = 256,
                 fixed_parameters: dict = {}) -> None:
        """
        Initialize the AfterglowData class. 
        This class is used to generate training data for the surrogate models. 
        The data is generated by running the afterglow model (see subclasses) on a set of parameters drawn from a given distribution.

        Args:
            outdir (str): The directory where the data is saved.
            n_training (int): Number of training samples.
            n_val (int): Number of validation samples.
            n_test (int): Number of test samples.
            parameter_distributions (dict, optional): Dictionary with distributions for parameters to sample. Defaults to None.
            jet_type (int, optional): Jet type as argument to afterglowpy. Defaults to -1. # TODO: double check jet type and catch errors
            tmin (float, optional): Starting time in days. Defaults to 1.0.
            tmax (float, optional): End time in days. Defaults to 1000.0.
            n_times (int, optional): Number of grid points for time. Defaults to 100.
            use_log_spacing (bool, optional): Whether to use log spacing in time. Defaults to True.
            numin (float, optional): Starting point for frequencies. Defaults to 1e9.
            numax (float, optional): End point for frequencies. Defaults to 2.5e18.
            n_nu (int, optional): Number of frequencies. Defaults to 256.
            fixed_parameters (dict, optional): Dictionary with parameters to keep fixed. Defaults to {}.

        Raises:
            ValueError: Unsupported jet type.
        """
        
        # FIXME: requires self.outfile to already be set...
        
        # Create outdir and outfile if they do not exist
        self.outdir = outdir
        if not os.path.exists(self.outdir):
            os.makedirs(self.outdir)
        self.outfile = os.path.join(self.outdir, outfile)

        # Save attributes
        self.n_training = n_training
        self.n_val = n_val
        self.n_test = n_test
        
        self.use_log_spacing = use_log_spacing
        self.tmin = tmin
        self.tmax = tmax
        self.n_times = n_times
        
        self.numin = numin
        self.numax = numax
        self.n_nu = n_nu
        
        # TODO: save the fixed parameters to the file as well?
        self.fixed_parameters = fixed_parameters

        if os.path.exists(self.outfile):
            self._read_file()
        else:
            self.jet_type = jet_type
            if self.jet_type not in [-1, 0]:
                raise ValueError(f"Jet type {jet_type} is not supported. Supported jet types are: [-1, 0]")
            
            self.initialize_times()
            self.initialize_nus()
            self.parameter_names = list(parameter_distributions.keys())
            self.parameter_distributions = parameter_distributions
            self._initialize_file()
            self.n_training_exists, self.n_val_exists, self.n_test_exists = 0, 0, 0
        
        print(f"Initialized fiesta.train.AfterglowData with following metatadata")
        space = " " * 3
        print(f"{space} Jet type: {self.jet_type}")
        print(f"{space} Parameters: {self.parameter_names}")
        print(f"{space} Times: {self.times[0]} {self.times[-1]} {len(self.times)}")
        print(f"{space} Nus: {self.nus[0]:.3e} {self.nus[-1]:.3e} {len(self.nus)}")
        print(f"{space} Parameter distributions: {self.parameter_distributions}")
        print(f"{space} Existing train, val, test: {self.n_training_exists}, {self.n_val_exists}, {self.n_test_exists} \n \n \n")

        # Create new data and save it to file
        self.get_raw_data(self.n_training, "train")
        self.get_raw_data(self.n_val, "val")
        self.get_raw_data(self.n_test, "test")

    def initialize_times(self) -> None:
        """
        Create the time grid and directly save it as attribute
        """
        if self.use_log_spacing:
            times = np.logspace(np.log10(self.tmin), np.log10(self.tmax), num=self.n_times)
        else:
            times = np.linspace(self.tmin, self.tmax, num=self.n_times)
        self.times = times
    
    def initialize_nus(self) -> None:
        """
        Create the frequency grid and directly save it as attribute
        """
        self.nus = np.logspace(np.log10(self.numin), np.log10(self.numax), self.n_nu)

    def _initialize_file(self):
        """
        Initialize the HDF5 file to which the data will be saved.
        """
        with h5py.File(self.outfile, "w") as f:
            f.create_dataset("times", data = self.times)
            f.create_dataset("nus", data = self.nus)
            f.create_dataset("parameter_names", data = self.parameter_names)
            f.create_dataset("parameter_distributions", data = str(self.parameter_distributions))
            f.create_dataset("jet_type", data = self.jet_type)
            f.create_group("train"); f.create_group("val"); f.create_group("test"); f.create_group("special_train")

    def get_raw_data(self, n: int, group: str):
        """
        Create raw data and save it to the HDF5 file.

        Args:
            n (int): Number of samples to create.
            group (str): Group to save the data to. Can be "train", "val" or "test".
        """
        
        # TODO: need to catch errors for group?
        training = True if group == "train" else False

        # Create raw data in chunks of chunk_size
        nchunks, rest = divmod(n, self.chunk_size)
        for chunk in tqdm.tqdm([*(nchunks*[self.chunk_size]), rest], desc = f"Calculating {nchunks+1} chunks of {group} data...", leave = True):
            if chunk == 0:
                continue
            X, y = self.create_raw_data(chunk, training)
            X, y = self.fix_nans(X, y)
            self._save_to_file(X, y, group)

    def fix_nans(self, 
                 X: Array[Float], 
                 y: Array[Float],
                 max_tries: int = 100,
                 warning_threshold: float = 0.1) -> tuple[Array[Float], Array[Float]]:
        """
        Replace nans in the output with new samples from the parameter space.

        Args:
            X (Array[Float]): Input array
            y (Array[Float]): Output array

        Returns:
            Array[Float]: Arrays with NaNs fixed
        """
        problematic = np.unique(np.where(np.isnan(y))[0])
        n = len(problematic)
        counter = 0
        
        while n > 0:
            if n > int(warning_threshold * len(X)):
                print(f"Warning: Found many nans for the parameter samples, in total {n} out of {len(X)} samples.")
            X_replacement, y_replacement = self.create_raw_data(n)
            X[problematic] = X_replacement
            y[problematic] = y_replacement
            problematic = np.unique(np.where(np.isnan(y))[0])
            n = len(problematic)
            counter += 1
            
            if counter > max_tries:
                raise ValueError(f"Could not fix all nans after {max_tries} tries -- double check the data")
    
        return X, y
    
    def _read_file(self):
        """
        Read the HDF5 file and save the data to the class attributes.
        """
        with h5py.File(self.outfile, "r") as f:
            self.jet_type = f["jet_type"][()]
            self.times = f["times"][:]
            self.nus = f["nus"][:]
            self.parameter_names = f["parameter_names"][:].astype(str).tolist()
            self.parameter_distributions = ast.literal_eval(f["parameter_distributions"][()].decode('utf-8'))
            try:
                self.n_training_exists = (f["train"]["X"].shape)[0]
            except KeyError:
                self.n_training_exists = 0
            try:
                self.n_val_exists = (f["val"]["X"].shape)[0]
            except KeyError:
                self.n_val_exists = 0
            try:
                self.n_test_exists = (f["test"]["X"].shape)[0]
            except KeyError:
                self.n_test_exists = 0

    def create_raw_data(self, n: int, training: bool = True):
        """
        Create draws X in the parameter space and run the afterglow model on it.
        
        Args:
            n (int): Number of samples to create.
            training (bool, optional): Whether the data is for training or not. Defaults to True.
        """
        # Create training data
        X_raw = np.empty((n, len(self.parameter_names)))
       
        if training:
            # FIXME: make getting the distributions cleaner
            for j, key in enumerate(self.parameter_names):
                a, b, distribution = self.parameter_distributions[key]
                if distribution == "uniform":
                    X_raw[:, j] = np.random.uniform(a, b, size = n)
                elif distribution == "loguniform":
                    X_raw[:, j] = np.exp(np.random.uniform(np.log(a), np.log(b), size = n))
        else:
            # FIXME: what if not uniform?
            for j, key in enumerate(self.parameter_distributions.keys()):
                a, b, _ = self.parameter_distributions[key]
                X_raw[:, j] = np.random.uniform(a, b, size = n)

        X_raw = self._fix_epsilons(X_raw)
        X_raw = self._fix_thetaWing(X_raw)

        X, y = self.run_afterglow_model(X_raw)
        return X, y
    
    def _fix_epsilons(self, X: Array[Float]) -> Array[Float]:
        """
        Ensure that epsilon_e + epsilon_B < 1.

        Args:
            X (Array[Float]): Input array to be fixed.
            
        Returns:
            Array[Float]: Fixed array.
        """
        epsilon_e_ind = self.parameter_names.index("log10_epsilon_e")
        epsilon_B_ind = self.parameter_names.index("log10_epsilon_B")
        epsilon_tot = (10 ** (X[:, epsilon_e_ind]) + 10 ** (X[:, epsilon_B_ind]))
        mask = epsilon_tot>=1 
        X[mask, epsilon_B_ind] += np.log10(0.99 / epsilon_tot[mask])
        X[mask, epsilon_e_ind] += np.log10(0.99 / epsilon_tot[mask])
        
        return X
    
    def _fix_thetaWing(self, X: Array[Float]) -> Array[Float]:
        """
        Ensure that thetaWing is smaller than pi/2.

        Args:
            X (Array[Float]): Input array to be fixed.
            
        Returns:
            Array[Float]: Fixed array.
        """
        if self.jet_type != -1:
            alphaw_ind = self.parameter_names.index("alphaWing")
            thetac_ind = self.parameter_names.index("thetaCore")
            mask = X[:, alphaw_ind] * X[:, thetac_ind] >= np.pi/2
            X[mask, alphaw_ind] = np.pi/2 * 1/X[mask, thetac_ind]
        return 
    
    def create_special_data(self,
                            X_raw: Array[Float],
                            label: str,
                            comment: str = None):
        """
        Create special training data with pre-specified parameters X. These will be stored in the 'special_train' hdf5 group.
        
        Args:
            X_raw (Array[Float]): Array with the parameters to run the afterglow model on.
            label (str): Label for the special training data.
            comment (str, optional): Comment for the special training data. Defaults to None.
        """
        
        X_raw = self._fix_epsilons(X_raw)
        X_raw = self._fix_thetaWing(X_raw)
        
        X, y = self.run_afterglow_model(X_raw)
        X, y = self.fix_nans(X,y)
        self._save_to_file(X, y, "special_train", label = label, comment= comment)

    def run_afterglow_model(self, X):
        raise NotImplementedError

    def _save_to_file(self, 
                      X: Array[Float],
                      y: Array[Float],
                      group: str,
                      label: str = None,
                      comment: str = None):
        """
        Save the data to a file

        Args:
            X (Array[Float]): Input data to be saved
            y (Array[Float]): Output data to be saved
            group (str): Group name to be used for saving
            label (str, optional): Label to give. Defaults to None.
            comment (str, optional): Comment to write. Defaults to None.
        """
        with h5py.File(self.outfile, "a") as f:
            # Check if the dataset already exists
            if "y" in f[group]: 
                Xset = f[group]["X"]
                Xset.resize(Xset.shape[0]+X.shape[0], axis = 0)
                Xset[-X.shape[0]:] = X

                yset = f[group]["y"]
                yset.resize(yset.shape[0]+y.shape[0], axis = 0)
                yset[-y.shape[0]:] = y
            
            # Check for special training data
            elif label is not None: 
                if label in f["special_train"]:
                    Xset = f["special_train"][label]["X"]
                    Xset.resize(Xset.shape[0] + X.shape[0], axis = 0)
                    Xset[-X.shape[0]:] = X

                    yset = f[group][label]["y"]
                    yset.resize(yset.shape[0] + y.shape[0], axis = 0)
                    yset[-y.shape[0]:] = y

                else: 
                    f["special_train"].create_group(label)
                    if comment is not None:
                        f["special_train"][label].attrs["comment"] = comment
                    f["special_train"][label].create_dataset("X", data = X, maxshape=(None, len(self.parameter_names)), chunks = (self.chunk_size, len(self.parameter_names)))
                    f["special_train"][label].create_dataset("y", data = y, maxshape=(None, len(self.times)*len(self.nus)), chunks = (self.chunk_size, len(self.times)*len(self.nus)))

            # Create a new dataset
            else: 
                f[group].create_dataset("X", data = X, maxshape=(None, len(self.parameter_names)), chunks = (self.chunk_size, len(self.parameter_names)))
                f[group].create_dataset("y", data = y, maxshape=(None, len(self.times)*len(self.nus)), chunks = (self.chunk_size, len(self.times)*len(self.nus)))

class AfterglowpyData(AfterglowData):
    """Class to create training data from afterglowpy"""
    
    n_pool: int
    chunk_size: int

    # TODO: does n_pool also need to be a part of afterglowdata?
    def __init__(self, n_pool: int, *args, **kwargs):
        self.n_pool = n_pool
        self.chunk_size = 1000
        
        kwargs["outfile"] = "afterglowpy_raw_data.h5"
        super().__init__(*args, **kwargs)


    def run_afterglow_model(self, X: Array[Float]):
        """
        Uses multiprocessing to run afterglowpy on the supplied parameters in X.
        
        Args:
            X (Array[Float]): Array with the parameters to run the afterglow model on.
        """
        
        y = np.empty((len(X), len(self.times)*len(self.nus)))
        afgpy = RunAfterglowpy(self.jet_type, self.times, self.nus, X, self.parameter_names, self.fixed_parameters)
        pool = Pool(processes=self.n_pool)
        jobs = [pool.apply_async(func=afgpy, args=(argument,)) for argument in range(len(X))]
        pool.close()
        for Idx, job in enumerate(tqdm.tqdm(jobs, desc = f"Computing {len(X)} afterglowpy calculations.", leave = False)):
            try:
                idx, out = job.get()
                y[idx] = out
            except:
                y[Idx] = np.full(len(self.times)*len(self.nus), np.nan)
        return X, y


class PyblastafterglowData(AfterglowData):
    """Class to create training data from Pyblastafterglow"""
    
    path_to_exec: str
    pbag_kwargs: dict
    rank: int
    chunk_size: int
    
    def __init__(self, 
                 path_to_exec: str,
                 pbag_kwargs: dict = None,
                 rank: int = 0,
                 *args, 
                 **kwargs):
        
        self.chunk_size = 10
        self.rank = rank
        self.path_to_exec = path_to_exec
        self.pbag_kwargs = pbag_kwargs
        
        kwargs["outfile"] = f"pyblastafterglow_raw_data_{rank}.h5"
        super().__init__(*args, **kwargs)


    def run_afterglow_model(self, X: Array[Float]):
        """
        Run in parallel with different mpi processes to run pyblastafterglow on the parameters in the array X.
        
        Args:
            X (Array[Float]): Array with the parameters to run the afterglow model on.
        """
        y = np.empty((len(X), len(self.times)*len(self.nus)))

        pbag = RunPyblastafterglow(self.jet_type,
                                   self.times, 
                                   self.nus, 
                                   X, 
                                   self.parameter_names, 
                                   self.fixed_parameters, 
                                   rank=self.rank, 
                                   path_to_exec=self.path_to_exec,
                                   **self.pbag_kwargs)
        
        for j in range(len(X)):
            try:
                idx, out = pbag(j)
                y[idx] = out
            except:
                try: 
                    # increase blast wave evolution time grid if there is an error
                    pbag.ntb = 3000 
                    idx, out = pbag(j)
                    y[idx] = out
                    pbag.ntb = self.pbag_kwargs["ntb"]
                except:
                    y[j] = np.full(len(self.times)*len(self.nus), np.nan)           
        return X, y
    
    def supplement_time(self, t_supp: Array[Float]):
        """
        Supplement the times to the existing data in the HDF5 file.

        Args:
            t_supp (Array[Float]): Time grid to supplement the existing data with.
        """
        self.times = t_supp

        for group in ["train", "val", "test"]:
            with h5py.File(self.outfile) as f:
                if "y" not in f[group].keys():
                    continue
                if f[group]["y"].shape[1] > f["times"].shape[0] * f["nus"].shape[0]:
                    continue
                X = f[group]["X"][:]

            _, y_new = self.run_afterglow_model(X)
            y_new = y_new.reshape(-1, len(self.nus), len(self.times))

            with h5py.File(self.outfile, "r+") as f:
                y_old = f[group]["y"][:]
                y_old = y_old.reshape(-1, f["nus"].shape[0], f["times"].shape[0])
                y = np.concatenate((y_new, y_old), axis=-1)

                new_time_shape = len(self.times) + f["times"].shape[0]
                y = y.reshape(-1, new_time_shape * len(self.nus))
                del f[group]["y"]
                f[group].create_dataset("y", data=y, maxshape=(None, new_time_shape*len(self.nus)), chunks = (self.chunk_size, new_time_shape*len(self.nus)) )
        

        with h5py.File(self.outfile,"r+") as f:
            t_old = f["times"][:]
            del f["times"]
            time = np.concatenate((t_supp, t_old))
            f.create_dataset("times", data=time)

class RunAfterglowpy:
    """Class to interface with afterglowpy and call it with the given parameters"""
    
    # TODO: make a base run class to avoid code duplication?
    
    def __init__(self, 
                 jet_type: int, 
                 times: Array[Float],
                 nus: Array[Float],
                 X: Array[Float],
                 parameter_names: list[str],
                 fixed_parameters: dict = {}):
        """
        Initialize the class

        Args:
            jet_type (int): Jet type as argument to afterglowpy.
            times (Array[Float]): Grid of times to evaluate the model at.
            nus (Array[Float]): Grid of frequencies to evaluate the model at.
            X (Array[Float]): Grid of parameters to evaluate the model at.
            parameter_names (list[str]): List of parameter names.
            fixed_parameters (dict, optional): Dictionary with parameters kept fixed. Defaults to {}.
        """
        
        self.jet_type = jet_type
        self.times = times
        # NOTE: afterglowpy takes time in seconds
        self._times_afterglowpy = self.times * days_to_seconds
        self.nus = nus
        self.X = X
        self.parameter_names = parameter_names
        self.fixed_parameters = fixed_parameters

    def _call_afterglowpy(self, params_dict: dict[str, float]):
        """
        Call afterglowpy to generate a single flux density output, for a given set of parameters. 
        Note that the parameters_dict should contain all the parameters that the model requires, as well as the nu value.
        The output will be a set of mJys.

        Args:
            Float[Array, "n_times"]: The flux density in mJys at the given times.
        """
        
        # Preprocess the params_dict into the format that afterglowpy expects, which is usually called Z
        Z = {}
        
        # TODO: getting and checking if everything is setup correctly outside of this function?
        
        Z["jetType"]  = params_dict.get("jetType", self.jet_type)
        Z["specType"] = params_dict.get("specType", 0)
        Z["z"] = params_dict.get("redshift", 0.0)
        Z["xi_N"] = params_dict.get("xi_N", 1.0)
        Z["counterjet"] = True
            
        Z["E0"]        = 10 ** params_dict["log10_E0"]
        Z["n0"]        = 10 ** params_dict["log10_n0"]
        Z["p"]         = params_dict["p"]
        Z["epsilon_e"] = 10 ** params_dict["log10_epsilon_e"]
        Z["epsilon_B"] = 10 ** params_dict["log10_epsilon_B"]
        Z["d_L"]       = dL_at_10pc # fix at 10 pc, so that AB magnitude equals absolute magnitude

        if "inclination_EM" in list(params_dict.keys()):
            Z["thetaObs"]  = params_dict["inclination_EM"]
        else:
            Z["thetaObs"]  = params_dict["thetaObs"]

        if self.jet_type == -1:
             Z["thetaCore"] = params_dict["thetaCore"]
        
        elif self.jet_type == 0:
             Z["thetaCore"] = params_dict["thetaCore"]
             Z["thetaWing"] = params_dict["thetaCore"]*params_dict["alphaWing"]

        elif self.jet_type == 4:
            Z["thetaCore"] = params_dict["thetaCore"]
            Z["thetaWing"] = params_dict["thetaCore"]*params_dict["alphaWing"]
            Z["b"] = params_dict["b"]
        
        else:
            raise ValueError(f"Provided jet type {self.jet_type} invalid.")
        
        # Afterglowpy returns flux in mJys
        tt, nunu = np.meshgrid(self._times_afterglowpy, self.nus)
        mJys = grb.fluxDensity(tt, nunu, **Z)
        return mJys

    def __call__(self, idx: int) -> tuple[int, Array[Float]]:
        param_dict = dict(zip(self.parameter_names, self.X[idx]))
        param_dict.update(self.fixed_parameters)
        mJys = self._call_afterglowpy(param_dict)
        return idx, np.log(mJys).flatten()


class RunPyblastafterglow:
    def __init__(self,
                 jet_type: int,
                 times: Array[Float],
                 nus: Array[Float],
                 X: Array[Float],
                 parameter_names: list[str],
                 fixed_parameters: dict = {},
                 rank: int = 0,
                 path_to_exec: str="./pba.out",
                 grb_resolution: int = 12,
                 ntb: int = 1000,
                 tb0: float = 1e1,
                 tb1: float = 1e11,
                 rtol: float = 1e-1,
                 loglevel: str = "err",
                 ):
        
        jet_conversion = {"-1": "tophat",
                          "0": "gaussian"}
        if jet_type not in [-1, 0]:
            raise ValueError(f"Jet type {jet_type} is not supported. Supported jet types are: [-1, 0]")
        self.jet_type = jet_conversion[str(jet_type)]
        
        # NOTE: pyblastafterglow takes seconds as input
        times_seconds = times * days_to_seconds

        # preparing the pyblastafterglow string argument for time array
        is_log_uniform = np.allclose(np.diff(np.log(times_seconds)), np.log(times_seconds[1])-np.log(times_seconds[0]), atol=0.01)
        if is_log_uniform:
            log_dt = np.log(times_seconds[1]) - np.log(times_seconds[0])
            # pyblastafterglow only takes the following string format
            self.lc_times = f'array logspace {times_seconds[0]:e} {np.exp(log_dt)*times_seconds[-1]:e} {len(times_seconds)}' 
        else:
            raise ValueError("Time array must be loguniform.")

        # preparing the pyblastafterglow string argument for frequency array
        log_dnu = np.log(nus[1]/nus[0])
        self.lc_freqs = f'array logspace {nus[0]:e} {np.exp(log_dnu)*nus[-1]:e} {len(nus)}'

        # Set as attributes
        self.X = X
        self.parameter_names = parameter_names
        self.fixed_parameters = fixed_parameters
        self.rank = rank
        self.path_to_exec = path_to_exec
        self.grb_resolution = grb_resolution
        self.ntb = ntb
        self.tb0 = tb0
        self.tb1 = tb1
        self.rtol = rtol
        self.loglevel = loglevel

    def _call_pyblastafterglow(self, params_dict: dict[str, float]):
        """
        Run pyblastafterglow to generate a single flux density output, for a given set of parameters. 
        Note that the parameters_dict should contain all the parameters that the model requires.
        The output will be a set of mJys.

        Args:
            Float[Array, "n_times"]: The flux density in mJys at the given times.
        """
        
        try:
            from PyBlastAfterglowMag.wrappers import run_grb
        except ImportError:
            raise ImportError("PyBlastAfterglowMag is not installed. Please install it from source")
        
        # Define jet structure (analytic; gaussian) -- 3 free parameters 
        struct = dict(
            struct= self.jet_type, # type of the structure tophat or gaussian
            Eiso_c=np.power(10, params_dict["log10_E0"]),  # isotropic equivalent energy of the burst 
            Gamma0c=params_dict["Gamma0"],    # lorentz factor of the core of the jet 
            M0c=-1.,         # mass of the ejecta (if -1 -- inferr from Eiso_c and Gamma0c)
            n_layers_a=self.grb_resolution    # resolution of the jet (number of individual blastwaves)
        )

        if self.jet_type == "tophat":
            struct["theta_c"] =  params_dict['thetaCore'] # half-opening angle of the winds of the jet
        
        elif self.jet_type == "gaussian":
            struct["theta_c"] =  params_dict['thetaCore'] # half-opening angle of the winds of the jet
            struct["theta_w"] = params_dict["thetaCore"] * params_dict["alphaWing"]
        
        else:
            raise ValueError(f"Provided jet type {self.jet_type} invalid.")

        # set model parameters
        P = dict(
                # main model parameters; Uniform ISM -- 2 free parameters
                main=dict(
                    d_l= dL_at_10pc, # luminosity distance to the source [cm], fix at 10 pc, so that AB magnitude equals absolute magnitude
                    z = params_dict.get("redshift", 0.0),   # redshift of the source (used in Doppler shifring and EBL table)
                    n_ism=np.power(10, params_dict["log10_n0"]), # ISM density [cm^-3] (assuming uniform)
                    theta_obs= params_dict["inclination_EM"], # observer angle [rad] (from pol to jet axis)  
                    lc_freqs= self.lc_freqs, # frequencies for light curve calculation
                    lc_times= self.lc_times, # times for light curve calculation
                    tb0=self.tb0, tb1=self.tb1, ntb=self.ntb, # burster frame time grid boundary, resolution, for the simulation
                ),

                # ejecta parameters; FS only -- 3 free parameters 
                grb=dict(
                    structure=struct, # structure of the ejecta
                    eps_e_fs=np.power(10, params_dict["log10_epsilon_e"]), # microphysics - FS - frac. energy in electrons
                    eps_b_fs=np.power(10, params_dict["log10_epsilon_B"]), # microphysics - FS - frac. energy in magnetic fields
                    p_fs= params_dict["p"], # microphysics - FS - slope of the injection electron spectrum
                    do_lc='yes',      # task - compute light curves
                    rtol_theta = self.rtol,
                    # save_spec='yes' # save comoving spectra 
                    # method_synchrotron_fs = 'Joh06',
                    # method_ne_fs = 'usenprime',
                    # method_ele_fs = 'analytic',
                    # method_comp_mode = 'observFlux'
                )
        )
        pba_run = run_grb(working_dir= os.getcwd() + f'/tmp_{self.rank}/', # directory to save/load from simulation data
                              P=P,                     # all parameters 
                              run=True,                # run code itself (if False, it will try to load results)
                              path_to_cpp=self.path_to_exec, # absolute path to the C++ executable of the code
                              loglevel=self.loglevel,         # logging level of the code (info or err)
                              process_skymaps=False    # process unstractured sky maps. Only useed if `do_skymap = yes`
                             )
        
        mJys = pba_run.GRB.get_lc()
        return mJys

    def __call__(self, idx):
        param_dict = dict(zip(self.parameter_names, self.X[idx]))
        param_dict.update(self.fixed_parameters)
        mJys = self._call_pyblastafterglow(param_dict)
        return  idx, np.log(mJys).flatten()
